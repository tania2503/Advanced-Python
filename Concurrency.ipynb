{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assigment 7: Concurrency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Website uptime__ is the time that a website or web service is available to the users over a given period.\n",
    "\n",
    "The task is to build an application that checks the uptime of websites. \n",
    "\n",
    "- The application should go over a list of website URLs and checks if those websites are up.\n",
    "- Instead of performing a classic HTTP GET request, it performs a HEAD request so that it does not affect traffic significantly.\n",
    "- If the HTTP status is in the danger ranges (400+, 500+), a message is casted. \n",
    "\n",
    "Here are some useful functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### _website uptimer_ ####\n",
    "\n",
    "import time\n",
    "import logging\n",
    "import requests\n",
    " \n",
    "class WebsiteDownException(Exception):\n",
    "    pass\n",
    " \n",
    "def ping_website(address, timeout=20):\n",
    "    \"\"\"\n",
    "    Check if a website is down. A website is considered down \n",
    "    if either the status_code >= 400 or if the timeout expires\n",
    "     \n",
    "    Throw a WebsiteDownException if any of the website down conditions are met\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = requests.head(address, timeout=timeout)\n",
    "        if response.status_code >= 400:\n",
    "            logging.warning(\"Website %s returned status_code=%s\" % (address, response.status_code))\n",
    "            raise WebsiteDownException()\n",
    "    except requests.exceptions.RequestException:\n",
    "        logging.warning(\"Timeout expired for website %s\" % address)\n",
    "        raise WebsiteDownException()\n",
    "         \n",
    "def check_website(address):\n",
    "    \"\"\"\n",
    "    Utility function: check if a website is down, if so, notify the user\n",
    "    \"\"\"\n",
    "    try:\n",
    "        ping_website(address)\n",
    "    except WebsiteDownException:\n",
    "        print('The websie '+address+' is down')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need a website list to try our system out. Create your own list or use the following one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "WEBSITE_LIST = [\n",
    "    'http://envato.com',\n",
    "    'http://amazon.co.uk',\n",
    "    'http://amazon.com',\n",
    "    'http://facebook.com',\n",
    "    'http://google.com',\n",
    "    'http://google.fr',\n",
    "    'http://google.es',\n",
    "    'http://google.co.uk',\n",
    "    'http://internet.org',\n",
    "    'http://gmail.com',\n",
    "    'http://stackoverflow.com',\n",
    "    'http://github.com',\n",
    "    'http://heroku.com',\n",
    "    'http://really-cool-available-domain.com',\n",
    "    'http://djangoproject.com',\n",
    "    'http://rubyonrails.org',\n",
    "    'http://basecamp.com',\n",
    "    'http://trello.com',\n",
    "    'http://yiiframework.com',\n",
    "    'http://shopify.com',\n",
    "    'http://another-really-interesting-domain.co',\n",
    "    'http://airbnb.com',\n",
    "    'http://instagram.com',\n",
    "    'http://snapchat.com',\n",
    "    'http://youtube.com',\n",
    "    'http://baidu.com',\n",
    "    'http://yahoo.com',\n",
    "    'http://live.com',\n",
    "    'http://linkedin.com',\n",
    "    'http://yndex.ru',\n",
    "    'http://netflix.com',\n",
    "    'http://wordpress.com',\n",
    "    'http://bing.com',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A serial version of the _website uptimer_ can be written as: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Website http://live.com returned status_code=405\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The websie http://live.com is down\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Website http://netflix.com returned status_code=405\n",
      "WARNING:root:Website http://bing.com returned status_code=405\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The websie http://netflix.com is down\n",
      "The websie http://bing.com is down\n",
      "Time for Serial: 5.274498701095581secs\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    " \n",
    "start_time = time.time()\n",
    " \n",
    "for address in WEBSITE_LIST:\n",
    "    check_website(address)\n",
    "         \n",
    "end_time = time.time()        \n",
    " \n",
    "print(\"Time for Serial: %ssecs\" % (end_time - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should build two versions of the _website uptimer_, one using threads and another using multiprocessing. Compare the time of each version and write a short explanation of what you are observing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### _website uptimer_ ####\n",
    "\n",
    "import time\n",
    "import logging\n",
    "import requests\n",
    " \n",
    "class WebsiteDownException(Exception):\n",
    "    pass\n",
    " \n",
    "def ping_website(address, timeout=20):\n",
    "    \"\"\"\n",
    "    Check if a website is down. A website is considered down \n",
    "    if either the status_code >= 400 or if the timeout expires\n",
    "     \n",
    "    Throw a WebsiteDownException if any of the website down conditions are met\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = requests.head(address, timeout=timeout)\n",
    "        if response.status_code >= 400:\n",
    "            logging.warning(\"Website %s returned status_code=%s\" % (address, response.status_code))\n",
    "            raise WebsiteDownException()\n",
    "    except requests.exceptions.RequestException:\n",
    "        logging.warning(\"Timeout expired for website %s\" % address)\n",
    "        raise WebsiteDownException()\n",
    "         \n",
    "def check_website_thread(q):\n",
    "    \"\"\"\n",
    "    Utility function: check if a website is down, if so, notify the user\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        web_link = q.get()\n",
    "        try:\n",
    "            ping_website(web_link)\n",
    "        except WebsiteDownException:\n",
    "            print('The websie '+web_link+' is down')\n",
    "        q.task_done()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Website http://live.com returned status_code=405\n",
      "WARNING:root:Website http://bing.com returned status_code=405\n",
      "WARNING:root:Website http://netflix.com returned status_code=405\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The websie http://live.com is down\n",
      "The websie http://bing.com is down\n",
      "The websie http://netflix.com is down\n",
      "Time for Serial: 1.304875135421753secs\n"
     ]
    }
   ],
   "source": [
    "from queue import Queue\n",
    "from threading import Thread\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "q = Queue()\n",
    "num_threads = 12\n",
    "\n",
    "for i in range(num_threads):\n",
    "    worker = Thread(target=check_website_thread, args=(q,))\n",
    "    worker.setDaemon(True) # this stop the threads when the program quits  \n",
    "    worker.start()         # start the threads\n",
    "\n",
    "for address in WEBSITE_LIST:\n",
    "    q.put(address)\n",
    "q.join()\n",
    "         \n",
    "end_time = time.time()        \n",
    " \n",
    "print(\"Time for Serial: %ssecs\" % (end_time - start_time))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "WEBSITE_LIST = [\n",
    "    'http://envato.com',\n",
    "    'http://amazon.co.uk',\n",
    "    'http://amazon.com',\n",
    "    'http://facebook.com',\n",
    "    'http://google.com',\n",
    "    'http://google.fr',\n",
    "    'http://google.es',\n",
    "    'http://google.co.uk',\n",
    "    'http://internet.org',\n",
    "    'http://gmail.com',\n",
    "    'http://stackoverflow.com',\n",
    "    'http://github.com',\n",
    "    'http://heroku.com',\n",
    "    'http://really-cool-available-domain.com',\n",
    "    'http://djangoproject.com',\n",
    "    'http://rubyonrails.org',\n",
    "    'http://basecamp.com',\n",
    "    'http://trello.com',\n",
    "    'http://yiiframework.com',\n",
    "    'http://shopify.com',\n",
    "    'http://another-really-interesting-domain.co',\n",
    "    'http://airbnb.com',\n",
    "    'http://instagram.com',\n",
    "    'http://snapchat.com',\n",
    "    'http://youtube.com',\n",
    "    'http://baidu.com',\n",
    "    'http://yahoo.com',\n",
    "    'http://live.com',\n",
    "    'http://linkedin.com',\n",
    "    'http://yndex.ru',\n",
    "    'http://netflix.com',\n",
    "    'http://wordpress.com',\n",
    "    'http://bing.com',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### _website uptimer_ ####\n",
    "\n",
    "import time\n",
    "import logging\n",
    "import requests\n",
    " \n",
    "class WebsiteDownException(Exception):\n",
    "    pass\n",
    " \n",
    "def ping_website(address, timeout=20):\n",
    "    \"\"\"\n",
    "    Check if a website is down. A website is considered down \n",
    "    if either the status_code >= 400 or if the timeout expires\n",
    "     \n",
    "    Throw a WebsiteDownException if any of the website down conditions are met\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = requests.head(address, timeout=timeout)\n",
    "        if response.status_code >= 400:\n",
    "            logging.warning(\"Website %s returned status_code=%s\" % (address, response.status_code))\n",
    "            raise WebsiteDownException()\n",
    "    except requests.exceptions.RequestException:\n",
    "        logging.warning(\"Timeout expired for website %s\" % address)\n",
    "        raise WebsiteDownException()\n",
    "         \n",
    "def check_website_mprocessing(address):\n",
    "    \"\"\"\n",
    "    Utility function: check if a website is down, if so, notify the user\n",
    "    \"\"\"\n",
    "    try:\n",
    "        ping_website(address)\n",
    "    except WebsiteDownException:\n",
    "        print('The websie '+address+' is down')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from multiprocessing.pool import Pool\n",
    " \n",
    "start_time = time.time()\n",
    "\n",
    "with Pool(8) as p:\n",
    "    p.map(check_website_mprocessing, WEBSITE_LIST)\n",
    "         \n",
    "end_time = time.time()        \n",
    " \n",
    "print(\"Time for Mprocessing: %ssecs\" % (end_time - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both the codes are giving similar timings - which is around 1.30 sec. This behavior mainly depends on the type of task that is being done. In case the task would have been CPU intensive than the multiprocessing might have run faster. In case of a task related to some API Threading might have been the winner. This task involves pinging websites on the internet and it involvs the internet much. So, the time for both the methods is quite similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
